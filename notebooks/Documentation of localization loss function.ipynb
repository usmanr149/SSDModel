{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f10aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../read_data/')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd1075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbox_utils import match_priors_with_gt, box_overlap_iou, convert_to_centre_dimensions_form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b3113",
   "metadata": {},
   "source": [
    "Create a 32 x 32 grid and initialize some ground truth boxes.\n",
    "\n",
    "The localization loss should only be calculated over ground truth box that where IOU > 0.5 over the default box.\n",
    "\n",
    "The tensorflow huberloss function averages the loss by the length of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59de9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuse we have a 8 x 8 box divided into 2 x 2 prior boxes\n",
    "\n",
    "image_size = 32\n",
    "boxes = []\n",
    "prior_boxes = []\n",
    "default_box_size  = 4\n",
    "\n",
    "for i in range(0, image_size // default_box_size,):\n",
    "    for j in range(0, image_size // default_box_size):\n",
    "        boxes.append([ j * default_box_size, i * default_box_size, \n",
    "                            (j + 1) * default_box_size, (i + 1) * default_box_size ])\n",
    "        prior_boxes.append( [ j * default_box_size + default_box_size // 2, i * default_box_size + default_box_size // 2, default_box_size, default_box_size ] )\n",
    "        \n",
    "gt_boxes = [[6, 10, 12, 20]]\n",
    "# gt_boxes = [[4, 4, 9, 9], [9, 9, 14 , 14], [24, 24, 29, 29]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f92618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x161f11550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.ones((image_size + 1, image_size + 1, 3))\n",
    "\n",
    "for box in boxes:\n",
    "    \n",
    "    start_x, start_y, end_x, end_y = box\n",
    "    \n",
    "    image = cv2.rectangle(image, [start_x, start_y], [end_x, end_y], (255, 0 , 0), thickness = 1)\n",
    "\n",
    "for box in gt_boxes:\n",
    "    \n",
    "    start_x, start_y, end_x, end_y = box  \n",
    "    image = cv2.rectangle(image, [start_x, start_y], [end_x, end_y], (255, 0, 255), thickness = 1)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae61ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = np.array(boxes, np.float32) / image_size\n",
    "prior_boxes = np.array(prior_boxes, np.float32) / image_size\n",
    "\n",
    "\n",
    "# gt_boxes = [[4, 4, 9, 9], [9, 9, 14 , 14], [24, 24, 29, 29]]\n",
    "gt_boxes = [[6, 10, 12, 20]]\n",
    "# gt_labels = [1, 2, 1]\n",
    "gt_labels = [1]\n",
    "\n",
    "gt_boxes_normalized = tf.constant([gt_boxes], tf.float32) / image_size\n",
    "\n",
    "gt_labels = tf.constant([gt_labels])\n",
    "\n",
    "actual_deltas, actual_labels = match_priors_with_gt(prior_boxes, boxes, gt_boxes_normalized, gt_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8edf3ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.015625 / 0.1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4c49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58920732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00021752, 0.00578268], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "pred_deltas = np.random.rand(1, 64, 4) * np.random.randint(-1, 2, size = (1, 64, 4))\n",
    "\n",
    "pred_deltas[0, 9] = [-0.015, 0.012, 0 , -0.031]\n",
    "pred_deltas[0, 54] = [0.15, 0.12, -0.0123 , -0.04]\n",
    "\n",
    "huber_loss = tf.keras.losses.Huber(\n",
    "    reduction=tf.keras.losses.Reduction.NONE\n",
    ")\n",
    "\n",
    "huber_loss([ [-0.015625, -0.015625, -0.03125 , -0.03125], [0.15, 0.12, -0.0123 , -0.04] ], \n",
    "           [ [-0.015, 0.012, 0 , -0.031], [-0.015625, -0.015625, -0.03125 , -0.03125]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712bae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_loss import SSDLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cc91be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = SSDLoss()\n",
    "\n",
    "loss.localization_loss(actual_deltas, pred_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf330d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e4cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
